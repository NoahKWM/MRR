print(log(best_lambda_lasso))
plot(cv_lasso_model$glmnet.fit, xvar = "lambda", main="Lasso Regression")
abline(h = 0, col = 6, lty = 3)
abline(v = log(best_lambda_lasso), col = 7, lty = 3)
legend("bottomleft", legend = c(colnames(X), "Zero", "Best Lambda"), col = 1:7, lty = 1)
print(log(best_lambda_lasso))
plot(cv_lasso_model$glmnet.fit, xvar = "lambda", main="Lasso Regression", xlim=c(-6, -3))
abline(h = 0, col = 6, lty = 3)
abline(v = log(best_lambda_lasso), col = 7, lty = 3)
legend("bottomleft", legend = c(colnames(X), "Zero", "Best Lambda"), col = 1:7, lty = 1)
print(log(best_lambda_lasso))
plot(cv_lasso_model$glmnet.fit, xvar = "lambda", main="Lasso Regression")
abline(h = 0, col = 6, lty = 3)
abline(v = log(best_lambda_lasso), col = 7, lty = 3)
legend("bottomleft", legend = c(colnames(X), "Zero", "Best Lambda"), col = 1:7, lty = 1)
print(log(best_lambda_lasso))
print(best_model_lasso)
# We split into 2 dataframe randomly
indice_train <- sample(1:nrow(cookies_data), 0.8 * nrow(cookies_data))
train_data <- cookies_data[indice_train, ]
test_data <- cookies_data[-indice_train, ]
# We define X & y for both dataframe
y_train <- train_data[, 1]
X_train <- train_data[, -1]
y_test <- test_data[, 1]
X_test <- test_data[, -1]
# We train the model with the best value for lambda
cv_ridge_model <- cv.glmnet(as.matrix(X_train), y_train, alpha = 0)
best_lambda_ridge <- cv_ridge_model$lambda.min
ridge_model <- glmnet(as.matrix(X_train), y_train, lambda = best_lambda_ridge, alpha = 0)
predictions_ridge <- predict(ridge_model, s = best_lambda_ridge, newx = as.matrix(X_test))
error_ridge <- sqrt(mean((predictions_ridge - y_test)^2))
print(paste("RMSE Ridge :", round(error_ridge, 2)))
# We split into 2 dataframe randomly
indice_train <- sample(1:nrow(cookies_data), 0.8 * nrow(cookies_data))
train_data <- cookies_data[indice_train, ]
test_data <- cookies_data[-indice_train, ]
# We define X & y for both dataframe
y_train <- train_data[, 1]
X_train <- train_data[, -1]
y_test <- test_data[, 1]
X_test <- test_data[, -1]
# We train the model with the best value for lambda
cv_ridge_model <- cv.glmnet(as.matrix(X_train), y_train, alpha = 0, grouped = FALSE)
best_lambda_ridge <- cv_ridge_model$lambda.min
ridge_model <- glmnet(as.matrix(X_train), y_train, lambda = best_lambda_ridge, alpha = 0)
predictions_ridge <- predict(ridge_model, s = best_lambda_ridge, newx = as.matrix(X_test))
error_ridge <- sqrt(mean((predictions_ridge - y_test)^2))
print(paste("RMSE Ridge :", round(error_ridge, 2)))
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls()); graphics.off()
cookies_data <- read.csv("cookies.csv")
# Computation (mean, standard deviation, minimum and maximum)
cookies_data$mean <- rowMeans(cookies_data[, 2:701])
cookies_data$stDev <- apply(cookies_data[, 2:701], 1, sd)
cookies_data$min <- apply(cookies_data[, 2:701], 1, min)
cookies_data$max <- apply(cookies_data[, 2:701], 1, max)
# Computation (slope)
# Function: compute_slope
# @param: spectrum_values of a cookie (here, column 2 to 701)
# @return: slope of the spectrum curve for a cookie
compute_slope <- function(spectrum_values) {
pos <- 1:length(spectrum_values)
lm_model <- lm(spectrum_values ~ pos)
slope <- coef(lm_model)[2]
return(slope)
}
cookies_data$slope <- apply(cookies_data[, 2:701], 1, compute_slope)
# Display of the new columns
head(cookies_data[,702:706])
# Only features and fat values are retrieved
cookies_features <- cookies_data[c("fat", "mean", "stDev", "slope", "min", "max")]
head(cookies_features)
X <- as.matrix(cookies_features[, -1]) # co-variables
y <- cookies_features$fat # target variable
# glmnet package is required
# install.packages("glmnet")
library(glmnet)
library(MASS)
# Cross validation
lambdas_log <- 10^seq(-4, 1, length.out = 100)
cv_ridge <- cv.glmnet(X, y, alpha=0, lambda = (lambdas_log), standardize = TRUE)
plot(cv_ridge)
best_lambda <- cv_ridge$lambda.min # lambda that gives the lowest MSE
print(paste("The best value for lambda is", best_lambda))
# AIC and BIC
n <- nrow(X)
p <- ncol(X)
aic <- n * log(cv_ridge$cvm) + 2 * p
bic <- n * log(cv_ridge$cvm) + log(n) * p
plot(log(cv_ridge$lambda), aic, col = "red1", type = "l", xlim = c(-8, -2), ylab = "Information Criterion")
lines(log(cv_ridge$lambda), bic, col = "blue1")
legend("bottomright", lwd = 1, col = c("red1", "blue1"), legend = c("AIC", "BIC"))
best_lambda_aic <- cv_ridge$lambda[which.min(aic)] # lambda that gives the lowest AIC
best_lambda_bic <- cv_ridge$lambda[which.min(bic)] # lambda that gives the lowest BIC
lambda_values <- c(best_lambda, best_lambda_aic, best_lambda_bic)
lambda_values
plot(cv_ridge$glmnet.fit, xvar = "lambda", ylim = c(-100, 100))
abline(h = 0, col = 6, lty = 3)
abline(v = log(best_lambda), col = 7, lty = 3)
legend("bottomleft", legend = c(colnames(X), "Zero", "Best Lambda"), col = 1:7, lty = 1)
best_model_ridge <- glmnet(X, y, alpha=0, lambda = best_lambda)
coef(best_model_ridge)
predictions <- predict(best_model_ridge, newx = X)
# RMSE
rmse <- sqrt(mean((predictions - y)^2))
print(paste("RMSE ridge model :", rmse))
# R^2
r_squared <- 1 - sum((y - predictions)^2) / sum((y - mean(y))^2)
print(paste("R^2 ridge model :", r_squared))
cv_lasso <- cv.glmnet(X, y, alpha=1, lambda = (lambdas_log), standardize = TRUE)
plot(cv_lasso)
best_lambda_lasso <- cv_lasso$lambda.min # lambda that gives the lowest MSE
print(paste("The best value for lambda is", best_lambda_lasso))
# AIC and BIC
n <- nrow(X)
p <- ncol(X)
lasso_aic <- n * log(cv_lasso$cvm) + 2 * p
lasso_bic <- n * log(cv_lasso$cvm) + log(n) * p
plot(log(cv_lasso$lambda), lasso_aic, col = "red1", type = "l", xlim = c(-8, -2), ylab = "Information Criterion")
lines(log(cv_lasso$lambda), lasso_bic, col = "blue1")
legend("bottomright", lwd = 1, col = c("red1", "blue1"), legend = c("AIC", "BIC"))
best_lambda_lasso_aic <- cv_lasso$lambda[which.min(lasso_aic)] # lambda that gives the lowest AIC
best_lambda_lasso_bic <- cv_lasso$lambda[which.min(lasso_bic)] # lambda that gives the lowest BIC
lambda_lasso_values <- c(best_lambda_lasso, best_lambda_lasso_aic, best_lambda_lasso_bic)
lambda_lasso_values
plot(cv_lasso$glmnet.fit, xvar = "lambda", ylim = c(-100, 100))
abline(h = 0, col = 6, lty = 3)
abline(v = log(best_lambda_lasso), col = 7, lty = 3)
legend("bottomleft", legend = c(colnames(X), "Zero", "Best Lambda"), col = 1:7, lty = 1)
best_model_lasso <- glmnet(X, y, alpha=1, lambda = best_lambda_lasso)
coef(best_model_lasso)
predictions <- predict(best_model_lasso, newx = X)
# RMSE
rmse <- sqrt(mean((predictions - y)^2))
print(paste("RMSE lasso model :", rmse))
# R^2
r_squared <- 1 - sum((y - predictions)^2) / sum((y - mean(y))^2)
print(paste("R^2 lasso model :", r_squared))
model_linear <- lm(y ~ X)
predictions_linear <- predict(model_linear, newdata = data.frame(X))
# RMSE
rmse_linear <- sqrt(mean((predictions_linear - y)^2))
print(paste("RMSE linear model :", rmse_linear))
# R^2
r_squared_linear <- 1 - sum((y - predictions_linear)^2) / sum((y - mean(y))^2)
print(paste("R^2 linear model :", r_squared_linear))
cookies_data <- read.csv("cookies.csv")
head(cookies_data)
dim(cookies_data)
library(glmnet)
y <- cookies_data[, 1]
X <- cookies_data[, -1]
cv_ridge_model <- cv.glmnet(as.matrix(X), y, alpha=0, standardize = TRUE)
plot(cv_ridge_model, main="Ridge Regression")
print(cv_ridge_model)
best_lambda <- cv_ridge_model$lambda.min
best_lambda_ridge_model <- best_lambda
print(paste("Best lambda :", best_lambda))
plot(cv_ridge_model$glmnet.fit, xvar = "lambda", main="Ridge Regression")
abline(h = 0, col = 6, lty = 3)
abline(v = log(best_lambda_ridge_model), col = 7, lty = 3)
legend("bottomleft", legend = c(colnames(X), "Zero", "Best Lambda"), col = 1:7, lty = 1)
final_ridge_model <- glmnet(as.matrix(X), y, alpha=0, lambda=best_lambda)
abs_coef <- abs(coef(final_ridge_model))
min(abs_coef)
paste("Number of value higher than 10^-1 : ", sum(abs_coef > 10^-1))
paste("Number of value higher than 10^-2 : ", sum(abs_coef > 10^-2))
paste("Number of value higher than 10^-3 : ", sum(abs_coef > 10^-3))
paste("Number of value higher than 10^-4 : ", sum(abs_coef > 10^-4))
cv_lasso_model <- cv.glmnet(as.matrix(X), y, alpha=1)
plot(cv_lasso_model, main="Lasso Regression")
print(cv_lasso_model)
best_lambda_lasso <- cv_lasso_model$lambda.min
best_model_lasso <- glmnet(as.matrix(X), y, lambda = best_lambda_lasso, alpha = 1)
plot(cv_lasso_model$glmnet.fit, xvar = "lambda", main="Lasso Regression")
abline(h = 0, col = 6, lty = 3)
abline(v = log(best_lambda_lasso), col = 7, lty = 3)
legend("bottomleft", legend = c(colnames(X), "Zero", "Best Lambda"), col = 1:7, lty = 1)
print(log(best_lambda_lasso))
print(best_model_lasso)
# We split into 2 dataframe randomly
indice_train <- sample(1:nrow(cookies_data), 0.8 * nrow(cookies_data))
train_data <- cookies_data[indice_train, ]
test_data <- cookies_data[-indice_train, ]
# We define X & y for both dataframe
y_train <- train_data[, 1]
X_train <- train_data[, -1]
y_test <- test_data[, 1]
X_test <- test_data[, -1]
# We train the model with the best value for lambda
cv_ridge_model <- cv.glmnet(as.matrix(X_train), y_train, alpha = 0, grouped = FALSE)
best_lambda_ridge <- cv_ridge_model$lambda.min
ridge_model <- glmnet(as.matrix(X_train), y_train, lambda = best_lambda_ridge, alpha = 0)
predictions_ridge <- predict(ridge_model, s = best_lambda_ridge, newx = as.matrix(X_test))
error_ridge <- sqrt(mean((predictions_ridge - y_test)^2))
print(paste("RMSE Ridge :", round(error_ridge, 2)))
# We split into 2 dataframe randomly
indice_train <- sample(1:nrow(cookies_data), 0.8 * nrow(cookies_data))
train_data <- cookies_data[indice_train, ]
test_data <- cookies_data[-indice_train, ]
# We define X & y for both dataframe
y_train <- train_data[, 1]
X_train <- train_data[, -1]
y_test <- test_data[, 1]
X_test <- test_data[, -1]
# We train the model with the best value for lambda
cv_lasso_model <- cv.glmnet(as.matrix(X_train), y_train, alpha = 1)
best_lambda <- cv_lasso_model$lambda.min
lasso_model <- glmnet(as.matrix(X_train), y_train, lambda = best_lambda, alpha = 1)
# We make prediction on the X_test
predictions_lasso <- predict(lasso_model, s = best_lambda, newx = as.matrix(X_test))
# We compute the RMSE
error_lasso  <- sqrt(mean((predictions_lasso - y_test)^2))
print(paste("RMSE :", round(error_lasso, 2)))
# We split into 2 dataframe randomly
indice_train <- sample(1:nrow(cookies_data), 0.8 * nrow(cookies_data))
train_data <- cookies_data[indice_train, ]
test_data <- cookies_data[-indice_train, ]
# We define X & y for both dataframe
y_train <- train_data[, 1]
X_train <- train_data[, -1]
y_test <- test_data[, 1]
X_test <- test_data[, -1]
# We train the model with the best value for lambda
cv_lasso_model <- cv.glmnet(as.matrix(X_train), y_train, alpha = 1, grouped = FALSE)
best_lambda <- cv_lasso_model$lambda.min
lasso_model <- glmnet(as.matrix(X_train), y_train, lambda = best_lambda, alpha = 1)
# We make prediction on the X_test
predictions_lasso <- predict(lasso_model, s = best_lambda, newx = as.matrix(X_test))
# We compute the RMSE
error_lasso  <- sqrt(mean((predictions_lasso - y_test)^2))
print(paste("RMSE :", round(error_lasso, 2)))
# We split into 2 dataframe randomly
indice_train <- sample(1:nrow(cookies_data), 0.8 * nrow(cookies_data))
train_data <- cookies_data[indice_train, ]
test_data <- cookies_data[-indice_train, ]
# We define X & y for both dataframe
y_train <- train_data[, 1]
X_train <- train_data[, -1]
y_test <- test_data[, 1]
X_test <- test_data[, -1]
# We train the model with the best value for lambda
cv_ridge_model <- cv.glmnet(as.matrix(X_train), y_train, alpha = 0, grouped = FALSE)
best_lambda_ridge <- cv_ridge_model$lambda.min
ridge_model <- glmnet(as.matrix(X_train), y_train, lambda = best_lambda_ridge, alpha = 0)
predictions_ridge <- predict(ridge_model, s = best_lambda_ridge, newx = as.matrix(X_test))
error_ridge <- sqrt(mean((predictions_ridge - y_test)^2))
print(paste("RMSE Ridge :", round(error_ridge, 2)))
# We split into 2 dataframe randomly
indice_train <- sample(1:nrow(cookies_data), 0.8 * nrow(cookies_data))
train_data <- cookies_data[indice_train, ]
test_data <- cookies_data[-indice_train, ]
# We define X & y for both dataframe
y_train <- train_data[, 1]
X_train <- train_data[, -1]
y_test <- test_data[, 1]
X_test <- test_data[, -1]
# We train the model with the best value for lambda
cv_lasso_model <- cv.glmnet(as.matrix(X_train), y_train, alpha = 1, grouped = FALSE)
best_lambda <- cv_lasso_model$lambda.min
lasso_model <- glmnet(as.matrix(X_train), y_train, lambda = best_lambda, alpha = 1)
# We make prediction on the X_test
predictions_lasso <- predict(lasso_model, s = best_lambda, newx = as.matrix(X_test))
# We compute the RMSE
error_lasso  <- sqrt(mean((predictions_lasso - y_test)^2))
print(paste("RMSE :", round(error_lasso, 2)))
?step
resall<-glm(fat~.,data=cookies_data,family=gaussian)
res0<-glm(fat~1,data=cookies_data,family=gaussian)
resfor<-step(res0,list(upper=resall),direction='forward', trace=0)
print(resfor)
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls()); graphics.off()
cookies_data <- read.csv("cookies.csv")
dim(cookies_data)
library(glmnet)
y <- cookies_data[, 1]
X <- cookies_data[, -1]
cv_ridge_model <- cv.glmnet(as.matrix(X), y, alpha=0, standardize = TRUE)
plot(cv_ridge_model, main="Ridge Regression")
print(cv_ridge_model)
best_lambda <- cv_ridge_model$lambda.min
best_lambda_ridge_model <- best_lambda
print(paste("Best lambda :", best_lambda))
plot(cv_ridge_model$glmnet.fit, xvar = "lambda", main="Ridge Regression", xlim=c(1.5, 7))
abline(h = 0, col = 6, lty = 3)
abline(v = log(best_lambda_ridge_model), col = 7, lty = 3)
legend("bottomleft", legend = c(colnames(X)), col = 1:700, lty = 1)
final_ridge_model <- glmnet(as.matrix(X), y, alpha=0, lambda=best_lambda)
abs_coef <- abs(coef(final_ridge_model)[-1])
min(abs_coef)
paste("Number of value higher than 10^-1 : ", sum(abs_coef > 10^-1))
paste("Number of value higher than 10^-2 : ", sum(abs_coef > 10^-2))
paste("Number of value higher than 10^-3 : ", sum(abs_coef > 10^-3))
paste("Number of value higher than 10^-4 : ", sum(abs_coef > 10^-4))
cv_lasso_model <- cv.glmnet(as.matrix(X), y, alpha=1)
plot(cv_lasso_model, main="Lasso Regression")
print(cv_lasso_model)
best_lambda_lasso <- cv_lasso_model$lambda.min
best_model_lasso <- glmnet(as.matrix(X), y, lambda = best_lambda_lasso, alpha = 1)
plot(cv_lasso_model$glmnet.fit, xvar = "lambda", main="Lasso Regression", xlim=c(-5.5, 0))
abline(h = 0, col = 6, lty = 3)
abline(v = log(best_lambda_lasso), col = 7, lty = 3)
legend("bottomleft", legend = c(colnames(X), "Zero", "Best Lambda"), col = 1:7, lty = 1)
print(log(best_lambda_lasso))
non_zero_coefficients <- (best_model_lasso$beta[which(best_model_lasso$beta != 0)])
non_zero_spectra <- (colnames(X)[which(best_model_lasso$beta != 0)])
data.frame(non_zero_spectra, non_zero_coefficients)
print(best_model_lasso)
# We split into 2 dataframe randomly
indice_train <- sample(1:nrow(cookies_data), 0.8 * nrow(cookies_data))
train_data <- cookies_data[indice_train, ]
test_data <- cookies_data[-indice_train, ]
# We define X & y for both dataframe
y_train <- train_data[, 1]
X_train <- train_data[, -1]
y_test <- test_data[, 1]
X_test <- test_data[, -1]
# We train the model with the best value for lambda
cv_ridge_model <- cv.glmnet(as.matrix(X_train), y_train, alpha = 0, grouped = FALSE)
best_lambda_ridge <- cv_ridge_model$lambda.min
ridge_model <- glmnet(as.matrix(X_train), y_train, lambda = best_lambda_ridge, alpha = 0)
predictions_ridge <- predict(ridge_model, s = best_lambda_ridge, newx = as.matrix(X_test))
error_ridge <- sqrt(mean((predictions_ridge - y_test)^2))
print(paste("RMSE Ridge :", round(error_ridge, 2)))
# We split into 2 dataframe randomly
indice_train <- sample(1:nrow(cookies_data), 0.8 * nrow(cookies_data))
train_data <- cookies_data[indice_train, ]
test_data <- cookies_data[-indice_train, ]
# We define X & y for both dataframe
y_train <- train_data[, 1]
X_train <- train_data[, -1]
y_test <- test_data[, 1]
X_test <- test_data[, -1]
# We train the model with the best value for lambda
cv_lasso_model <- cv.glmnet(as.matrix(X_train), y_train, alpha = 1, grouped = FALSE)
best_lambda <- cv_lasso_model$lambda.min
lasso_model <- glmnet(as.matrix(X_train), y_train, lambda = best_lambda, alpha = 1)
# We make prediction on the X_test
predictions_lasso <- predict(lasso_model, s = best_lambda, newx = as.matrix(X_test))
# We compute the RMSE
error_lasso  <- sqrt(mean((predictions_lasso - y_test)^2))
print(paste("RMSE :", round(error_lasso, 2)))
seed(123)
set.seed(123)
# We split into 2 dataframe randomly
indice_train <- sample(1:nrow(cookies_data), 0.8 * nrow(cookies_data))
train_data <- cookies_data[indice_train, ]
test_data <- cookies_data[-indice_train, ]
# We define X & y for both dataframe
y_train <- train_data[, 1]
X_train <- train_data[, -1]
y_test <- test_data[, 1]
X_test <- test_data[, -1]
# We train the model with the best value for lambda
cv_lasso_model <- cv.glmnet(as.matrix(X_train), y_train, alpha = 1, grouped = FALSE)
best_lambda <- cv_lasso_model$lambda.min
lasso_model <- glmnet(as.matrix(X_train), y_train, lambda = best_lambda, alpha = 1)
# We make prediction on the X_test
predictions_lasso <- predict(lasso_model, s = best_lambda, newx = as.matrix(X_test))
# We compute the RMSE
error_lasso  <- sqrt(mean((predictions_lasso - y_test)^2))
print(paste("RMSE :", round(error_lasso, 2)))
set.seed(1)
# We split into 2 dataframe randomly
indice_train <- sample(1:nrow(cookies_data), 0.8 * nrow(cookies_data))
train_data <- cookies_data[indice_train, ]
test_data <- cookies_data[-indice_train, ]
# We define X & y for both dataframe
y_train <- train_data[, 1]
X_train <- train_data[, -1]
y_test <- test_data[, 1]
X_test <- test_data[, -1]
# We train the model with the best value for lambda
cv_lasso_model <- cv.glmnet(as.matrix(X_train), y_train, alpha = 1, grouped = FALSE)
best_lambda <- cv_lasso_model$lambda.min
lasso_model <- glmnet(as.matrix(X_train), y_train, lambda = best_lambda, alpha = 1)
# We make prediction on the X_test
predictions_lasso <- predict(lasso_model, s = best_lambda, newx = as.matrix(X_test))
# We compute the RMSE
error_lasso  <- sqrt(mean((predictions_lasso - y_test)^2))
print(paste("RMSE :", round(error_lasso, 2)))
set.seed(1234)
# We split into 2 dataframe randomly
indice_train <- sample(1:nrow(cookies_data), 0.8 * nrow(cookies_data))
train_data <- cookies_data[indice_train, ]
test_data <- cookies_data[-indice_train, ]
# We define X & y for both dataframe
y_train <- train_data[, 1]
X_train <- train_data[, -1]
y_test <- test_data[, 1]
X_test <- test_data[, -1]
# We train the model with the best value for lambda
cv_lasso_model <- cv.glmnet(as.matrix(X_train), y_train, alpha = 1, grouped = FALSE)
best_lambda <- cv_lasso_model$lambda.min
lasso_model <- glmnet(as.matrix(X_train), y_train, lambda = best_lambda, alpha = 1)
# We make prediction on the X_test
predictions_lasso <- predict(lasso_model, s = best_lambda, newx = as.matrix(X_test))
# We compute the RMSE
error_lasso  <- sqrt(mean((predictions_lasso - y_test)^2))
print(paste("RMSE :", round(error_lasso, 2)))
set.seed(0)
# We split into 2 dataframe randomly
indice_train <- sample(1:nrow(cookies_data), 0.8 * nrow(cookies_data))
train_data <- cookies_data[indice_train, ]
test_data <- cookies_data[-indice_train, ]
# We define X & y for both dataframe
y_train <- train_data[, 1]
X_train <- train_data[, -1]
y_test <- test_data[, 1]
X_test <- test_data[, -1]
# We train the model with the best value for lambda
cv_lasso_model <- cv.glmnet(as.matrix(X_train), y_train, alpha = 1, grouped = FALSE)
best_lambda <- cv_lasso_model$lambda.min
lasso_model <- glmnet(as.matrix(X_train), y_train, lambda = best_lambda, alpha = 1)
# We make prediction on the X_test
predictions_lasso <- predict(lasso_model, s = best_lambda, newx = as.matrix(X_test))
# We compute the RMSE
error_lasso  <- sqrt(mean((predictions_lasso - y_test)^2))
print(paste("RMSE :", round(error_lasso, 2)))
set.seed(2)
# We split into 2 dataframe randomly
indice_train <- sample(1:nrow(cookies_data), 0.8 * nrow(cookies_data))
train_data <- cookies_data[indice_train, ]
test_data <- cookies_data[-indice_train, ]
# We define X & y for both dataframe
y_train <- train_data[, 1]
X_train <- train_data[, -1]
y_test <- test_data[, 1]
X_test <- test_data[, -1]
# We train the model with the best value for lambda
cv_lasso_model <- cv.glmnet(as.matrix(X_train), y_train, alpha = 1, grouped = FALSE)
best_lambda <- cv_lasso_model$lambda.min
lasso_model <- glmnet(as.matrix(X_train), y_train, lambda = best_lambda, alpha = 1)
# We make prediction on the X_test
predictions_lasso <- predict(lasso_model, s = best_lambda, newx = as.matrix(X_test))
# We compute the RMSE
error_lasso  <- sqrt(mean((predictions_lasso - y_test)^2))
print(paste("RMSE :", round(error_lasso, 2)))
# We split into 2 dataframe randomly
indice_train <- sample(1:nrow(cookies_data), 0.8 * nrow(cookies_data))
train_data <- cookies_data[indice_train, ]
test_data <- cookies_data[-indice_train, ]
# We define X & y for both dataframe
y_train <- train_data[, 1]
X_train <- train_data[, -1]
y_test <- test_data[, 1]
X_test <- test_data[, -1]
# We train the model with the best value for lambda
cv_lasso_model <- cv.glmnet(as.matrix(X_train), y_train, alpha = 1, grouped = FALSE)
best_lambda <- cv_lasso_model$lambda.min
lasso_model <- glmnet(as.matrix(X_train), y_train, lambda = best_lambda, alpha = 1)
# We make prediction on the X_test
predictions_lasso <- predict(lasso_model, s = best_lambda, newx = as.matrix(X_test))
# We compute the RMSE
error_lasso  <- sqrt(mean((predictions_lasso - y_test)^2))
print(paste("RMSE :", round(error_lasso, 2)))
# We split into 2 dataframe randomly
indice_train <- sample(1:nrow(cookies_data), 0.8 * nrow(cookies_data))
train_data <- cookies_data[indice_train, ]
test_data <- cookies_data[-indice_train, ]
# We define X & y for both dataframe
y_train <- train_data[, 1]
X_train <- train_data[, -1]
y_test <- test_data[, 1]
X_test <- test_data[, -1]
# We train the model with the best value for lambda
cv_lasso_model <- cv.glmnet(as.matrix(X_train), y_train, alpha = 1, grouped = FALSE)
best_lambda <- cv_lasso_model$lambda.min
lasso_model <- glmnet(as.matrix(X_train), y_train, lambda = best_lambda, alpha = 1)
# We make prediction on the X_test
predictions_lasso <- predict(lasso_model, s = best_lambda, newx = as.matrix(X_test))
# We compute the RMSE
error_lasso  <- sqrt(mean((predictions_lasso - y_test)^2))
print(paste("RMSE :", round(error_lasso, 2)))
# We split into 2 dataframe randomly
indice_train <- sample(1:nrow(cookies_data), 0.8 * nrow(cookies_data))
train_data <- cookies_data[indice_train, ]
test_data <- cookies_data[-indice_train, ]
# We define X & y for both dataframe
y_train <- train_data[, 1]
X_train <- train_data[, -1]
y_test <- test_data[, 1]
X_test <- test_data[, -1]
# We train the model with the best value for lambda
cv_lasso_model <- cv.glmnet(as.matrix(X_train), y_train, alpha = 1, grouped = FALSE)
best_lambda <- cv_lasso_model$lambda.min
lasso_model <- glmnet(as.matrix(X_train), y_train, lambda = best_lambda, alpha = 1)
# We make prediction on the X_test
predictions_lasso <- predict(lasso_model, s = best_lambda, newx = as.matrix(X_test))
# We compute the RMSE
error_lasso  <- sqrt(mean((predictions_lasso - y_test)^2))
print(paste("RMSE :", round(error_lasso, 2)))
# We split into 2 dataframe randomly
indice_train <- sample(1:nrow(cookies_data), 0.8 * nrow(cookies_data))
train_data <- cookies_data[indice_train, ]
test_data <- cookies_data[-indice_train, ]
# We define X & y for both dataframe
y_train <- train_data[, 1]
X_train <- train_data[, -1]
y_test <- test_data[, 1]
X_test <- test_data[, -1]
# We train the model with the best value for lambda
cv_lasso_model <- cv.glmnet(as.matrix(X_train), y_train, alpha = 1, grouped = FALSE)
best_lambda <- cv_lasso_model$lambda.min
lasso_model <- glmnet(as.matrix(X_train), y_train, lambda = best_lambda, alpha = 1)
# We make prediction on the X_test
predictions_lasso <- predict(lasso_model, s = best_lambda, newx = as.matrix(X_test))
# We compute the RMSE
error_lasso  <- sqrt(mean((predictions_lasso - y_test)^2))
print(paste("RMSE :", round(error_lasso, 2)))
